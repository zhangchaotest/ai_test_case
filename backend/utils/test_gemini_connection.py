# backend/utils/test_gemini_connection.py
import os
import asyncio
from autogen_ext.models.openai import OpenAIChatCompletionClient
from autogen_core.models import UserMessage
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
# # --- 1. é…ç½®ä»£ç† (æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ç«¯å£) ---
# os.environ["http_proxy"] = "http://127.0.0.1:7890"
# os.environ["https_proxy"] = "http://127.0.0.1:7890"


async def test_gemini():
    print("1. æ­£åœ¨åˆå§‹åŒ–å®¢æˆ·ç«¯...")

    # è‡ªåŠ¨è¯»å–ç¯å¢ƒå˜é‡ï¼Œæˆ–è€…åœ¨è¿™é‡Œå¡«å…¥
    api_key = os.environ.get("GEMINI_API_KEY")
    if not api_key:
        print("âŒ é”™è¯¯: æ‰¾ä¸åˆ° GEMINI_API_KEY")
        return

    try:
        # åˆå§‹åŒ–
        client = OpenAIChatCompletionClient(
            model="gemini-3-pro-preview",
            api_key=api_key,
            base_url="https://generativelanguage.googleapis.com/v1beta/openai/",
            timeout=30,

            # ğŸ”¥ğŸ”¥ğŸ”¥ æ ¸å¿ƒä¿®å¤ï¼šå¿…é¡»åŠ ä¸Šè¿™ä¸ª model_info å‚æ•°
            # å‘Šè¯‰ AutoGenï¼šâ€œè™½ç„¶è¿™ä¸æ˜¯ GPT-4ï¼Œä½†å®ƒæ”¯æŒè¿™äº›åŠŸèƒ½ï¼Œè¯·æ”¾è¡Œâ€
            model_info={
                "vision": False,
                "function_calling": True,
                "json_output": True,
                "family": "unknown"  # æˆ–è€… "gemini"
            }
        )

        print("2. æ­£åœ¨å‘é€è¯·æ±‚ (æ‰“æ‹›å‘¼)...")

        response = await client.create([
            UserMessage(content="ä½ å¥½ï¼Œè¯·å›å¤'è¿æ¥æˆåŠŸ'è¿™å››ä¸ªå­—ã€‚", source="user")
        ])

        print(f"âœ… 3. è¿æ¥æˆåŠŸï¼Gemini å›å¤:\n{response.content}")

    except Exception as e:
        print(f"âŒ è¿æ¥å¤±è´¥: {e}")
        # å¦‚æœæ˜¯ 404ï¼Œå¯èƒ½æ˜¯ base_url ä¸å¯¹æˆ–è€…æ¨¡å‹åä¸å¯¹


if __name__ == "__main__":
    asyncio.run(test_gemini())