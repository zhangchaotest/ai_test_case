import json
import re
import traceback

from autogen_agentchat.teams import RoundRobinGroupChat
from autogen_agentchat.conditions import TextMentionTermination
from autogen_agentchat.agents import AssistantAgent
from autogen_agentchat.ui import Console

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from backend.agents.llm_factory import get_gemini_client
from backend.utils.stream_utils import AutoGenStreamProcessor, format_sse
from backend.database.case_db import save_case,get_existing_case_titles
from backend.database.requirement_db import save_analyzed_point


# -------------------------------------------------------------------------
# é…ç½®åŒºåŸŸ
# -------------------------------------------------------------------------

# åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
gemini_client = get_gemini_client()

# Agent æ˜¾ç¤ºåç§°æ˜ å°„ï¼ˆç”¨äºå‰ç«¯å±•ç¤ºä¸­æ–‡åï¼‰
AGENT_NAMES_MAP = {
    "test_generator": "âœï¸ ç”¨ä¾‹è®¾è®¡ä¸“å®¶",
    "test_reviewer": "ğŸ§ è´¨é‡è¯„å®¡ç»„é•¿",
    "user": "ç”¨æˆ·æŒ‡ä»¤"
}

# å·¥å…·æ˜¾ç¤ºåç§°æ˜ å°„
TOOL_NAMES_MAP = {
    "save_case": "ğŸ’¾ æ•°æ®åº“å…¥åº“",
    "save_analyzed_point": "ğŸ“ åŠŸèƒ½ç‚¹æ‹†è§£å…¥åº“" # æ–°å¢
}

# -------------------------------------------------------------------------
# Agent å®šä¹‰åŒºåŸŸ
# -------------------------------------------------------------------------

def create_test_generator(target_count: int = 5):
    """
    åˆ›å»ºç”¨ä¾‹ç”Ÿæˆ Agent (Generator)
    :param target_count: ç›®æ ‡ç”Ÿæˆæ•°é‡
    :return:
    """
    print(f"ğŸ” [DEBUG] æ­£åœ¨åˆ›å»º Generator Agent, ç›®æ ‡æ•°é‡: {target_count}")  # <--- åŸ‹ç‚¹ 1

    return AssistantAgent(
        name="test_generator",
        model_client=gemini_client,
        system_message=f"""
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æµ‹è¯•å·¥ç¨‹å¸ˆã€‚
        
        ã€ä»»åŠ¡ç›®æ ‡ã€‘
        é’ˆå¯¹ç»™å®šçš„åŠŸèƒ½ç‚¹ï¼Œè®¡çº¦ **{target_count}** ä¸ªæµ‹è¯•ç”¨ä¾‹ã€‚
        
        ã€ç”Ÿæˆç­–ç•¥ã€‘
        1. ä¼˜å…ˆè¦†ç›–ï¼šP0çº§æ ¸å¿ƒåŠŸèƒ½ > å¸¸è§å¼‚å¸¸åœºæ™¯ > å…³é”®è¾¹ç•Œå€¼ã€‚
        2. **ä¸è¦** ç”Ÿæˆè¿‡äºç”Ÿåƒ»æˆ–é‡å¤çš„ç”¨ä¾‹ï¼ˆå¦‚ç½‘ç»œæ–­å¼€ã€æœåŠ¡å™¨ç‰©ç†æŸåç­‰ï¼‰ã€‚
        3. è¯·ä¸€æ¬¡æ€§å°†è¿™äº›ç”¨ä¾‹çš„ JSON ç»“æ„è¾“å‡ºå®Œæ¯•ï¼Œä¸è¦åˆ†æ‰¹æ¬¡è¾“å‡ºã€‚
        
        ã€æ ¼å¼è¦æ±‚ã€‘
        è¾“å‡ºæ ‡å‡† JSON æ ¼å¼çš„æ­¥éª¤ (step_id, action, expected)ã€‚
        - "case_title": ç”¨ä¾‹æ ‡é¢˜ (å¿…é¡»æœ‰ï¼Œä¸”ç®€æ´æ˜äº†)
        - "steps": æ­¥éª¤åˆ—è¡¨ [{{"step_id": 1, "action": "...", "expected": "..."}}]
        - "priority": ä¼˜å…ˆçº§ (P0-P2)
        - "case_type": ç±»å‹ (åŠŸèƒ½æµ‹è¯•ç”¨ä¾‹/åå‘æµ‹è¯•ç”¨ä¾‹/è¾¹ç•Œå€¼æµ‹è¯•ç”¨ä¾‹)

        ä¸è¦è¾“å‡º markdown ä»£ç å—ï¼Œç›´æ¥è¾“å‡ºç»“æ„åŒ–ä¿¡æ¯ã€‚
        """
    )


def create_test_reviewer():
    """
    åˆ›å»ºç”¨ä¾‹è¯„å®¡ Agent (Reviewer)
    æ‹¥æœ‰å…¥åº“å·¥å…·æƒé™
    """

    return AssistantAgent(
        name="test_reviewer",
        model_client=gemini_client,
        tools=[save_case],  # å·¥å…·éœ€è¦å¼•å…¥ db_tools
        system_message=f"""
        ä½ æ˜¯æµ‹è¯•ç»„é•¿ã€‚
        
        ã€æ‰§è¡Œæµç¨‹ã€‘
        1. å®¡æŸ¥ Generator ç”Ÿæˆçš„ç”¨ä¾‹ã€‚
        2. å¦‚æœç”¨ä¾‹æœ‰æ•ˆï¼Œ**ç«‹å³è°ƒç”¨å·¥å…·** `save_verified_test_case` è¿›è¡Œå…¥åº“ã€‚
        3. **é‡è¦ï¼š** å½“æœ¬æ‰¹æ¬¡ç”¨ä¾‹å…¨éƒ¨ä¿å­˜å®Œæ¯•åï¼Œ**å¿…é¡»** ç«‹å³å›å¤å…³é”®è¯ "TERMINATE" æ¥ç»“æŸä»»åŠ¡ã€‚
        4. ä¸è¦åœ¨è¿™ä¸ªæ—¶å€™è®© Generator ç»§ç»­ç”Ÿæˆæ–°çš„ç”¨ä¾‹ï¼Œç›´æ¥ç»“æŸã€‚
        """
    )

# -------------------------------------------------------------------------
# è¾…åŠ©è§£æå‡½æ•°
# -------------------------------------------------------------------------

def parse_generator_output(content: str):
    """
    [ä¸šåŠ¡è§£æå™¨] ä¸“é—¨è§£æ 'test_generator' çš„æ–‡æœ¬è¾“å‡º
    ç”¨äºåœ¨å‰ç«¯æ—¥å¿—ä¸­å±•ç¤ºâ€œæ­£åœ¨æ„æ€xxxç”¨ä¾‹â€
    """
    # å°è¯•æå– case_title æˆ– title å­—æ®µ
    # å…¼å®¹ "case_title": "xxx" å’Œ "title": "xxx"
    titles = re.findall(r'["\'](case_)?title["\']\s*:\s*["\'](.*?)["\']', content, re.IGNORECASE)

    # re.findall è¿”å›çš„æ˜¯å…ƒç»„åˆ—è¡¨ [('case_', 'æ ‡é¢˜1'), ('', 'æ ‡é¢˜2')]ï¼Œéœ€è¦æå–ç¬¬äºŒä¸ªå…ƒç´ 
    clean_titles = [t[1] for t in titles]

    if clean_titles:
        count = len(clean_titles)
        title_str = "ã€".join(clean_titles[:2])
        if count > 2: title_str += f" ç­‰ {count} ä¸ª"
        return f"æ­£åœ¨æ„æ€ç”¨ä¾‹ï¼šã€{title_str}ã€‘"

    if len(content) > 50:
        return "æ­£åœ¨è§£æéœ€æ±‚å¹¶æ„å»º JSON æ•°æ®..."

    return "æ­£åœ¨æ„æ€æµ‹è¯•åœºæ™¯..."

async def run_generation_task(req_id: int, feature_name: str, desc: str):
    """è§¦å‘ AutoGen æµç¨‹"""
    generator = create_test_generator()
    reviewer = create_test_reviewer()

    termination = TextMentionTermination("TERMINATE")
    team = RoundRobinGroupChat([generator, reviewer], termination_condition=termination, max_turns=8)

    task_prompt = f"""
    ã€ä»»åŠ¡ã€‘ä¸ºåŠŸèƒ½ç‚¹ç¼–å†™æµ‹è¯•ç”¨ä¾‹å¹¶å…¥åº“ã€‚
    åŠŸèƒ½ID: {req_id}
    åŠŸèƒ½åç§°: {feature_name}
    æè¿°: {feature_name}

    æ³¨æ„ï¼šä¿å­˜æ—¶ requirement_id å¿…é¡»ä¸º {req_id}ã€‚
    """

    # è¿è¡Œ
    await Console(team.run_stream(task=task_prompt))
    print(f"--- å¤„ç†ç»“æŸ ---")

    return True

async def run_stream_task(req_id: int, feature_name: str, desc: str, target_count: int = 5, mode: str = "new"):
    """
    ä¸šåŠ¡å…¥å£å‡½æ•°ï¼šç»„è£… Team -> å¯åŠ¨æµ -> ç§»äº¤å¤„ç†å™¨

    :param req_id: éœ€æ±‚ID
    :param feature_name: éœ€æ±‚åç§°
    :param desc: éœ€æ±‚æè¿°
    :param target_count: ç›®æ ‡ç”Ÿæˆæ•°é‡
    :param mode: 'new' (å…¨æ–°ç”Ÿæˆ) æˆ– 'append' (è¿½åŠ ç”Ÿæˆ)
    """
    print(f"ğŸš€ [DEBUG] è¿›å…¥ run_stream_task. ID={req_id}, Count={target_count}, Mode={mode}")

    # --- 1. å‘é€åˆå§‹åŒ–ç³»ç»Ÿé€šçŸ¥ (SSE) ---
    start_info = {
        "type": "log",
        "source": "ç³»ç»Ÿé€šçŸ¥",
        "content": f"âœ… è·å–éœ€æ±‚æˆåŠŸ\nğŸ“Œ éœ€æ±‚æ ‡é¢˜ï¼š{feature_name}\nğŸ¯ ç›®æ ‡æ•°é‡ï¼š{target_count} æ¡ ({'å¢é‡æ¨¡å¼' if mode == 'append' else 'å…¨é‡æ¨¡å¼'})"
    }
    yield format_sse("message", json.dumps(start_info, ensure_ascii=False))

    prepare_info = {
        "type": "log",
        "source": "ç³»ç»Ÿé€šçŸ¥",
        "content": "ğŸš€ æ­£åœ¨åˆå§‹åŒ–æ™ºèƒ½ä½“å›¢é˜Ÿ (Generator & Reviewer)..."
    }
    yield format_sse("message", json.dumps(prepare_info, ensure_ascii=False))

    try:
        # --- 2. æ ¹æ®æ¨¡å¼æ„å»º Prompt ä¸Šä¸‹æ–‡ ---
        existing_context = ""
        focus_instruction = "ä¼˜å…ˆè¦†ç›–æ ¸å¿ƒä¸šåŠ¡æµç¨‹ã€P0çº§åŠŸèƒ½ã€‚"

        if mode == "append":
            # å¢é‡æ¨¡å¼ï¼šæŸ¥å‡ºå·²æœ‰ç”¨ä¾‹ï¼Œé˜²æ­¢é‡å¤
            existing_titles = get_existing_case_titles(req_id)
            existing_json = json.dumps(existing_titles, ensure_ascii=False)

            existing_context = f"""
            ã€å·²å­˜åœ¨ç”¨ä¾‹åˆ—è¡¨ã€‘
            æ•°æ®åº“ä¸­å·²ç»æœ‰äº†ä»¥ä¸‹ç”¨ä¾‹ï¼Œè¯·**ç»å¯¹ä¸è¦é‡å¤**ï¼š
             {existing_json}
             """

            focus_instruction = """
             è¯·ä¸“æ³¨äº **æŸ¥æ¼è¡¥ç¼º**ï¼š
             1. é‡ç‚¹è¡¥å……ï¼š**å¼‚å¸¸åœºæ™¯**ã€**è¾¹ç•Œå€¼**ã€**å®‰å…¨æ€§**ã€**æ€§èƒ½å‹åŠ›** ç›¸å…³çš„ç”¨ä¾‹ã€‚
             2. é¿å¼€å·²æœ‰çš„æ­£å¸¸æµç¨‹ã€‚
             """

        # --- 3. åŠ¨æ€é…ç½®è½®æ¬¡ ---
        # å‡è®¾æ¯è½®èƒ½ç”Ÿæˆ 3-5 æ¡ï¼Œè®¡ç®—éœ€è¦çš„æœ€å¤§è½®æ¬¡ï¼Œé˜²æ­¢æˆªæ–­
        dynamic_turns = max(6, int(target_count / 3) + 4)
        print(f"âš™ï¸ [DEBUG] Team ç»„è£…å®Œæˆï¼Œæœ€å¤§è½®æ¬¡: {dynamic_turns}")

        # --- 4. ç»„è£… AutoGen Team ---
        generator = create_test_generator(target_count)
        reviewer = create_test_reviewer()
        termination = TextMentionTermination("TERMINATE")

        team = RoundRobinGroupChat(
            [generator, reviewer],
            termination_condition=termination,
            max_turns=dynamic_turns
        )

        task_prompt = f"""
        ã€ä»»åŠ¡ã€‘ä¸ºåŠŸèƒ½ç‚¹ç¼–å†™æµ‹è¯•ç”¨ä¾‹å¹¶å…¥åº“ã€‚
        åŠŸèƒ½ID: {req_id}
        åŠŸèƒ½åç§°: {feature_name}
        æè¿°: {desc}
        
        ã€å½“å‰æ¨¡å¼ã€‘ï¼š{'ğŸ”¥ å¢é‡è¡¥å……æ¨¡å¼' if mode == 'append' else 'ğŸš€ å…¨æ–°ç”Ÿæˆæ¨¡å¼'}
        ç›®æ ‡ç”Ÿæˆæ•°é‡ï¼š**{target_count} æ¡å·¦å³**ã€‚
        
        {existing_context}
        
        ã€ç”Ÿæˆç­–ç•¥ã€‘
        {focus_instruction}
        
        ã€æ‰§è¡Œè¦æ±‚ã€‘
        1. ä¿å­˜æ—¶ requirement_id å¿…é¡»ä¸º {req_id}ã€‚
        2. ç›®æ ‡ç”Ÿæˆæ•°é‡ï¼š**{target_count} æ¡å·¦å³**ã€‚ã€‚
        3. å¦‚æœæ•°é‡è¾ƒå¤šï¼Œä½ å¯ä»¥åˆ†å¤šæ¬¡ï¼ˆå¤šè½®å¯¹è¯ï¼‰ç”Ÿæˆï¼Œæ¯æ¬¡ç”Ÿæˆ 5 æ¡ï¼Œç›´åˆ°å‡‘å¤Ÿæ•°é‡ã€‚
        
        ã€é‡è¦æ‰§è¡ŒæŒ‡ä»¤ã€‘
        Generatorï¼Œè¯·ç«‹å³å¼€å§‹å·¥ä½œï¼
        è¯·å…ˆå›å¤ä¸€å¥ï¼šâ€œæ”¶åˆ°ï¼Œæ­£åœ¨ä¸º [ID:{req_id}] ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹...â€ï¼Œç„¶åç´§æ¥ç€è¾“å‡º JSON æ•°æ®ã€‚
        **ä¸è¦ä¿æŒæ²‰é»˜ï¼**

        """

        print(f"ğŸš€ [Stream] å¼€å§‹å¤„ç† ID: {req_id}")

        # --- 5. åˆå§‹åŒ–é€šç”¨æµå¼å¤„ç†å™¨ ---
        processor = AutoGenStreamProcessor(
            agent_names=AGENT_NAMES_MAP,
            tool_names=TOOL_NAMES_MAP,
            # æ³¨å†Œç‰¹å®šçš„è§£æé€»è¾‘
            custom_text_parsers={
                "test_generator": parse_generator_output
            }
        )
        # --- 6. å¯åŠ¨æµå¹¶ç§»äº¤å¤„ç† ---
        # team.run_stream è¿”å›çš„æ˜¯åŸå§‹è¿­ä»£å™¨ï¼Œç›´æ¥ä¼ ç»™ processor è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†
        raw_stream = team.run_stream(task=task_prompt)

        async for sse_event in processor.process_stream(raw_stream):
            yield sse_event

        print("âœ… [DEBUG] run_stream_task æ‰§è¡Œå®Œæ¯•")


    except Exception as e:
        # --- 7. å…¨å±€å¼‚å¸¸æ•è· ---
        traceback.print_exc()
        print(f"âŒ [FATAL ERROR] ä¸šåŠ¡é€»è¾‘å±‚å´©æºƒ: {e}")

        # å‘é€é”™è¯¯æ¶ˆæ¯ç»™å‰ç«¯
        err_json = json.dumps({
            "type": "log",
            "source": "åç«¯å´©æºƒ",
            "content": f"ç³»ç»Ÿé”™è¯¯: {str(e)}"
        }, ensure_ascii=False)
        yield format_sse("message", err_json)

        # å‘é€ç©ºçš„ç»“æŸä¿¡å·ï¼Œé¿å…å‰ç«¯æ— é™ç­‰å¾…
        yield format_sse("finish", "{}")


# å®šä¹‰éœ€æ±‚åˆ†æ Agent
def create_requirement_analyst():
    return AssistantAgent(
        name="req_analyst",
        model_client=gemini_client,
        tools=[save_analyzed_point],  # ç»‘å®šæ–°å·¥å…·
        system_message="""
        ä½ æ˜¯ä¸€ä¸ªèµ„æ·±äº§å“ç»ç†å’Œéœ€æ±‚åˆ†æå¸ˆã€‚

        ã€ä»»åŠ¡ç›®æ ‡ã€‘
        è¯»å–ç”¨æˆ·çš„åŸå§‹éœ€æ±‚æ–‡æœ¬ï¼ˆå¯èƒ½åŒ…å«è¡¥å……æŒ‡ä»¤ï¼‰ï¼Œå°†å…¶æ‹†è§£ä¸ºç»†ç²’åº¦çš„â€œåŠŸèƒ½ç‚¹â€ã€‚

        ã€æ‰§è¡Œæ­¥éª¤ã€‘
        1. åˆ†æç”¨æˆ·è¾“å…¥çš„åŸå§‹éœ€æ±‚ã€‚
        2. å°†å¤§æ®µæ–‡æœ¬æ‹†è§£ä¸ºç‹¬ç«‹çš„ã€å¯æµ‹è¯•çš„åŠŸèƒ½ç‚¹ (Feature)ã€‚
        3. å¯¹æ¯ä¸ªåŠŸèƒ½ç‚¹ï¼Œè°ƒç”¨å·¥å…· `save_analyzed_point` è¿›è¡Œä¿å­˜ã€‚

        ã€å·¥å…·å‚æ•°è¦æ±‚ã€‘
        - project_id: (ä»ä»»åŠ¡ä¸­è·å–)
        - module_name: æ ¹æ®åŠŸèƒ½å½’ç±» (å¦‚ï¼šç”¨æˆ·ä¸­å¿ƒã€è®¢å•æ¨¡å—)
        - feature_name: åŠŸèƒ½åç§° (ç®€ç»ƒ)
        - description: è¯¦ç»†æè¿°å’ŒéªŒæ”¶æ ‡å‡†
        - priority: P0/P1/P2
        - source_content: (å¡«å…¥ç”¨æˆ·è¾“å…¥çš„åŸå§‹éœ€æ±‚ç‰‡æ®µï¼Œç”¨äºè¿½æº¯)

        ã€ç»“æŸã€‘
        æ‰€æœ‰åŠŸèƒ½ç‚¹æ‹†è§£å¹¶ä¿å­˜å®Œæ¯•åï¼Œå›å¤ TERMINATEã€‚
        """
    )


# 2. å®šä¹‰éœ€æ±‚åˆ†ææµå¼ä»»åŠ¡
async def run_requirement_analysis_stream(project_id: int, raw_req: str, instruction: str = ""):
    print(f"ğŸš€ [Analysis Stream] Project: {project_id}")

    # åˆå§‹åŒ–
    analyst = create_requirement_analyst()
    # è¿™é‡Œä¸éœ€è¦ Reviewerï¼Œåˆ†æå¸ˆè‡ªå·±æ‹†è§£å³å¯ï¼Œæˆ–è€…ä½ å¯ä»¥åŠ ä¸€ä¸ª Reviewer æ¥å®¡æ ¸æ‹†è§£è´¨é‡
    # ä¸ºäº†ç®€åŒ–ï¼Œè¿™é‡Œç”¨å•äººæ¨¡å¼æˆ–è€…è‡ªè¨€è‡ªè¯­æ¨¡å¼ï¼Œä½† RoundRobin éœ€è¦è‡³å°‘2äººï¼Œ
    # æˆ‘ä»¬å¤ç”¨ä¹‹å‰çš„ UserProxy æ€æƒ³ï¼Œæˆ–è€…åˆ›å»ºä¸€ä¸ª dummy userã€‚
    # ä¸ºäº†æ–¹ä¾¿ï¼Œæˆ‘ä»¬å¤ç”¨ Reviewer ä½†ä¸ç»™å®ƒå·¥å…·ï¼Œåªè®©å®ƒè´Ÿè´£ç»“æŸã€‚
    reviewer = AssistantAgent(
        name="req_reviewer",
        model_client=gemini_client,
        system_message="ä½ è´Ÿè´£ç¡®è®¤åˆ†æå¸ˆæ˜¯å¦å·²å®Œæˆæ‰€æœ‰æ‹†è§£ã€‚å¦‚æœå®Œæˆï¼Œå›å¤ TERMINATEã€‚"
    )

    termination = TextMentionTermination("TERMINATE")
    team = RoundRobinGroupChat([analyst, reviewer], termination_condition=termination, max_turns=10)

    task_prompt = f"""
    ã€éœ€æ±‚åˆ†æä»»åŠ¡ã€‘
    é¡¹ç›®ID: {project_id}

    ã€åŸå§‹éœ€æ±‚å†…å®¹ã€‘
    {raw_req}

    ã€è¡¥å……æŒ‡ä»¤ã€‘
    {instruction}

    è¯·å¼€å§‹æ‹†è§£åŠŸèƒ½ç‚¹å¹¶å…¥åº“ã€‚
    æ³¨æ„ï¼šè°ƒç”¨ save_analyzed_point æ—¶ï¼ŒåŠ¡å¿…å°† project_id={project_id} å’Œ source_content (åŸå§‹éœ€æ±‚æ‘˜è¦) å¡«å…¥ã€‚
    """

    # ... (ä½¿ç”¨ä¸ run_stream_task ç›¸åŒçš„ processor é€»è¾‘) ...
    # æˆ‘ä»¬å¯ä»¥å¤ç”¨ AutoGenStreamProcessorï¼Œåªéœ€è¦æ³¨å†Œæ–°çš„è§£æå™¨å³å¯

    processor = AutoGenStreamProcessor(
        agent_names={"req_analyst": "ğŸ§ éœ€æ±‚åˆ†æå¸ˆ", "req_reviewer": "âœ… æµç¨‹ç¡®è®¤"},
        tool_names=TOOL_NAMES_MAP
    )

    # å‘é€å¼€åœºç™½
    yield format_sse("message", json.dumps({
        "type": "log", "source": "ç³»ç»Ÿ", "content": "æ­£åœ¨å¯åŠ¨éœ€æ±‚åˆ†æå¼•æ“..."
    }, ensure_ascii=False))

    async for sse in processor.process_stream(team.run_stream(task=task_prompt)):
        yield sse