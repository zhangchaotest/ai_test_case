#!/usr/bin/env python
# -*- coding: UTF-8 -*-
"""
@Project ï¼šai_test_case_fast 
@File    ï¼šcase_agent.py
@Author  ï¼šå¼ è¶…
@Date    ï¼š2025/12/22 09:20
@Desc    ï¼š
"""
# backend/agents/case_agent.py

import json
import re
import traceback

from autogen_agentchat.teams import RoundRobinGroupChat
from autogen_agentchat.conditions import TextMentionTermination
from autogen_agentchat.agents import AssistantAgent

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from backend.agents.llm_factory import get_gemini_client
from backend.database.case_db import save_case, get_existing_case_titles
from backend.database.prompt_db import get_prompt_by_id
from backend.utils.stream_utils import AutoGenStreamProcessor, format_sse

# å¯¼å…¥æ–°å¢æ¨¡å—
from backend.agents.prompt_manager import PromptManager
from backend.agents.test_dimension import TestDimensionManager
from backend.agents.context_manager import ContextManager

# ğŸ”¥ 1. ç¡®ä¿å¤´éƒ¨å¯¼å…¥äº†è¿™ä¸¤ä¸ª DB æ–¹æ³•
from backend.database.requirement_db import get_batch_functional_points
from backend.database.requirement_db import get_batch_breakdown_items  # å¦‚æœä¹‹å‰æœ‰é’ˆå¯¹æ‹†è§£è¡¨çš„æ‰¹é‡é€»è¾‘
# -------------------------------------------------------------------------
# é…ç½®åŒºåŸŸ
# -------------------------------------------------------------------------

# åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
gemini_client = get_gemini_client()

# Agent æ˜¾ç¤ºåç§°æ˜ å°„ï¼ˆç”¨äºå‰ç«¯å±•ç¤ºä¸­æ–‡åï¼‰
AGENT_NAMES_MAP = {
    "test_generator": "âœï¸ ç”¨ä¾‹è®¾è®¡ä¸“å®¶",
    "test_reviewer": "ğŸ§ è´¨é‡è¯„å®¡ç»„é•¿",
    "user": "ç”¨æˆ·æŒ‡ä»¤"
}

# å·¥å…·æ˜¾ç¤ºåç§°æ˜ å°„
TOOL_NAMES_MAP = {
    "save_case": "ğŸ’¾ æ•°æ®åº“å…¥åº“"
}

# åˆå§‹åŒ–æ–°å¢ç®¡ç†å™¨
prompt_manager = PromptManager()
dimension_manager = TestDimensionManager()
context_manager = ContextManager()


# -------------------------------------------------------------------------
# Agent å®šä¹‰åŒºåŸŸ
# -------------------------------------------------------------------------

def create_test_generator(target_count: int = 5, domain='base', prompt_id: int = None):
    """
    åˆ›å»ºç”¨ä¾‹ç”Ÿæˆ Agent (Generator)
    :param target_count: ç›®æ ‡ç”Ÿæˆæ•°é‡
    :param domain: é¢†åŸŸç±»å‹
    :param prompt_id: æç¤ºè¯ID
    """
    print(f"ğŸ” [DEBUG] æ­£åœ¨åˆ›å»º Generator Agent, ç›®æ ‡æ•°é‡: {target_count}")

    # è·å–æç¤ºè¯
    if prompt_id:
        prompt = get_prompt_by_id(prompt_id)
        if prompt:
            system_message = prompt['content'].replace('{target_count}', str(target_count))
            print(f"ğŸ“ ä½¿ç”¨è‡ªå®šä¹‰æç¤ºè¯: {prompt['name']}")
        else:
            system_message = prompt_manager.get_prompt('generator', domain, target_count=target_count)
            print("âš ï¸  æç¤ºè¯IDä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯")
    else:
        system_message = prompt_manager.get_prompt('generator', domain, target_count=target_count)

    return AssistantAgent(
        name="test_generator",
        model_client=gemini_client,
        system_message=system_message
    )


def create_test_reviewer(domain='base', prompt_id: int = None):
    """
    åˆ›å»ºç”¨ä¾‹è¯„å®¡ Agent (Reviewer)
    æ‹¥æœ‰å…¥åº“å·¥å…·æƒé™
    :param domain: é¢†åŸŸç±»å‹
    :param prompt_id: æç¤ºè¯ID
    """
    # è·å–æç¤ºè¯
    if prompt_id:
        prompt = get_prompt_by_id(prompt_id)
        if prompt:
            system_message = prompt['content']
            print(f"ğŸ“ ä½¿ç”¨è‡ªå®šä¹‰è¯„å®¡æç¤ºè¯: {prompt['name']}")
        else:
            system_message = prompt_manager.get_prompt('reviewer', domain)
            print("âš ï¸  æç¤ºè¯IDä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤è¯„å®¡æç¤ºè¯")
    else:
        system_message = prompt_manager.get_prompt('reviewer', domain)

    return AssistantAgent(
        name="test_reviewer",
        model_client=gemini_client,
        tools=[save_case],  # ç»‘å®šç”¨ä¾‹ä¿å­˜å·¥å…·
        system_message=system_message
    )


# -------------------------------------------------------------------------
# è¾…åŠ©è§£æå‡½æ•°
# -------------------------------------------------------------------------

def parse_generator_output(content: str):
    """
    [ä¸šåŠ¡è§£æå™¨] ä¸“é—¨è§£æ 'test_generator' çš„æ–‡æœ¬è¾“å‡º
    ç”¨äºåœ¨å‰ç«¯æ—¥å¿—ä¸­å±•ç¤ºâ€œæ­£åœ¨æ„æ€xxxç”¨ä¾‹â€
    """
    # å°è¯•æå– case_title æˆ– title å­—æ®µ
    titles = re.findall(r'["\'](case_)?title["\']\s*:\s*["\'](.*?)["\']', content, re.IGNORECASE)

    # re.findall è¿”å›çš„æ˜¯å…ƒç»„åˆ—è¡¨ [('case_', 'æ ‡é¢˜1'), ('', 'æ ‡é¢˜2')]ï¼Œéœ€è¦æå–ç¬¬äºŒä¸ªå…ƒç´ 
    clean_titles = [t[1] for t in titles]

    if clean_titles:
        count = len(clean_titles)
        title_str = "ã€".join(clean_titles[:2])
        if count > 2: title_str += f" ç­‰ {count} ä¸ª"
        return f"æ­£åœ¨æ„æ€ç”¨ä¾‹ï¼šã€{title_str}ã€‘"

    if len(content) > 50:
        return "æ­£åœ¨è§£æéœ€æ±‚å¹¶æ„å»º JSON æ•°æ®..."

    return "æ­£åœ¨æ„æ€æµ‹è¯•åœºæ™¯..."


# -------------------------------------------------------------------------
# ä¸»ä¸šåŠ¡æµç¨‹ (Case Generation)
# -------------------------------------------------------------------------

async def run_case_generation_stream(req_id: int, feature_name: str, desc: str, target_count: int = 5,
                                     mode: str = "new", domain='base', prompt_id: int = None):
    """
    ç”¨ä¾‹ç”Ÿæˆæµå¼ä»»åŠ¡å…¥å£

    :param req_id: éœ€æ±‚ID
    :param feature_name: éœ€æ±‚åç§°
    :param desc: éœ€æ±‚æè¿°
    :param target_count: ç›®æ ‡ç”Ÿæˆæ•°é‡
    :param mode: 'new' (å…¨æ–°ç”Ÿæˆ) æˆ– 'append' (è¿½åŠ ç”Ÿæˆ)
    :param domain: é¢†åŸŸç±»å‹ ('base', 'web', 'api' ç­‰)
    """
    print(f"ğŸš€ [Case Stream] å¼€å§‹å¤„ç† ID: {req_id}, Mode: {mode}")

    # --- 1. å‘é€åˆå§‹åŒ–ç³»ç»Ÿé€šçŸ¥ (SSE) ---
    start_info = {
        "type": "log",
        "source": "ç³»ç»Ÿé€šçŸ¥",
        "content": f"âœ… è·å–éœ€æ±‚æˆåŠŸ\nğŸ“Œ éœ€æ±‚æ ‡é¢˜ï¼š{feature_name}\nğŸ¯ ç›®æ ‡æ•°é‡ï¼š{target_count} æ¡ ({'å¢é‡æ¨¡å¼' if mode == 'append' else 'å…¨é‡æ¨¡å¼'})"
    }
    yield format_sse("message", json.dumps(start_info, ensure_ascii=False))

    prepare_info = {
        "type": "log",
        "source": "ç³»ç»Ÿé€šçŸ¥",
        "content": "ğŸš€ æ­£åœ¨åˆå§‹åŒ–æ™ºèƒ½ä½“å›¢é˜Ÿ (Generator & Reviewer)..."
    }
    yield format_sse("message", json.dumps(prepare_info, ensure_ascii=False))

    try:
        # --- 2. æ ¹æ®æ¨¡å¼æ„å»º Prompt ä¸Šä¸‹æ–‡ ---
        existing_context = ""
        focus_instruction = "ä¼˜å…ˆè¦†ç›–æ ¸å¿ƒä¸šåŠ¡æµç¨‹ã€P0çº§åŠŸèƒ½ã€‚"

        if mode == "append":
            # å¢é‡æ¨¡å¼ï¼šæŸ¥å‡ºå·²æœ‰ç”¨ä¾‹ï¼Œé˜²æ­¢é‡å¤
            # æ³¨æ„ï¼šè¿™é‡Œçš„ get_existing_case_titles æ¥è‡ª backend.database.case_db
            existing_titles = get_existing_case_titles(req_id)
            existing_json = json.dumps(existing_titles, ensure_ascii=False)

            existing_context = f"""
            ã€å·²å­˜åœ¨ç”¨ä¾‹åˆ—è¡¨ã€‘
            æ•°æ®åº“ä¸­å·²ç»æœ‰äº†ä»¥ä¸‹ç”¨ä¾‹ï¼Œè¯·**ç»å¯¹ä¸è¦é‡å¤**ï¼š
            {existing_json}
            """

            focus_instruction = """
            è¯·ä¸“æ³¨äº **æŸ¥æ¼è¡¥ç¼º**ï¼š
            1. é‡ç‚¹è¡¥å……ï¼š**å¼‚å¸¸åœºæ™¯**ã€**è¾¹ç•Œå€¼**ã€**å®‰å…¨æ€§**ã€**æ€§èƒ½å‹åŠ›** ç›¸å…³çš„ç”¨ä¾‹ã€‚
            2. é¿å¼€å·²æœ‰çš„æ­£å¸¸æµç¨‹ã€‚
            """

        # --- 3. åŠ¨æ€é…ç½®è½®æ¬¡ ---
        # å‡è®¾æ¯è½®èƒ½ç”Ÿæˆ 3-5 æ¡ï¼Œè®¡ç®—éœ€è¦çš„æœ€å¤§è½®æ¬¡ï¼Œé˜²æ­¢æˆªæ–­
        dynamic_turns = max(6, int(target_count / 3) + 4)
        print(f"âš™ï¸ [DEBUG] Team ç»„è£…å®Œæˆï¼Œæœ€å¤§è½®æ¬¡: {dynamic_turns}")

        # --- 4. ç”Ÿæˆæµ‹è¯•ç»´åº¦çŸ©é˜µ --- 
        req = {'feature_name': feature_name, 'description': desc}
        test_matrix = dimension_manager.generate_test_matrix(req)
        
        # --- 5. è·å–ä¸Šä¸‹æ–‡ä¿¡æ¯ --- 
        context = context_manager.get_context(req_id, req)
        
        # --- 6. æ„å»ºæµ‹è¯•ç»´åº¦å’Œä¸Šä¸‹æ–‡ä¿¡æ¯ --- 
        dimension_info = "\n\nã€æµ‹è¯•ç»´åº¦ã€‘\n"
        for dim in test_matrix:
            dimension_info += f"- {dim['name']}: {dim['description']} (ä¼˜å…ˆçº§: {dim['priority']})\n"
        
        context_info = ""
        if context['existing_cases']:
            context_info += "\n\nã€å·²å­˜åœ¨ç”¨ä¾‹ã€‘\n"
            for title in context['existing_cases'][:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                context_info += f"- {title}\n"
            if len(context['existing_cases']) > 5:
                context_info += f"... ç­‰ {len(context['existing_cases'])} ä¸ªç”¨ä¾‹\n"
        
        if context['coverage_gaps']:
            context_info += "\nã€è¦†ç›–ç›²åŒºã€‘\n"
            for gap in context['coverage_gaps']:
                context_info += f"- {gap}\n"

        # --- 7. ç»„è£… AutoGen Team ---
        generator = create_test_generator(target_count, domain, prompt_id)
        reviewer = create_test_reviewer(domain, prompt_id)
        termination = TextMentionTermination("TERMINATE")

        team = RoundRobinGroupChat(
            [generator, reviewer],
            termination_condition=termination,
            max_turns=dynamic_turns
        )

        task_prompt = f"""
        ã€ä»»åŠ¡ã€‘ä¸ºåŠŸèƒ½ç‚¹ç¼–å†™æµ‹è¯•ç”¨ä¾‹å¹¶å…¥åº“ã€‚
        åŠŸèƒ½ID: {req_id}
        åŠŸèƒ½åç§°: {feature_name}
        æè¿°: {desc}

        ã€å½“å‰æ¨¡å¼ã€‘ï¼š{'ğŸ”¥ å¢é‡è¡¥å……æ¨¡å¼' if mode == 'append' else 'ğŸš€ å…¨æ–°ç”Ÿæˆæ¨¡å¼'}
        ç›®æ ‡ç”Ÿæˆæ•°é‡ï¼š**{target_count} æ¡å·¦å³**ã€‚

        {existing_context}
        {dimension_info}
        {context_info}

        ã€ç”Ÿæˆç­–ç•¥ã€‘
        {focus_instruction}

        ã€æ‰§è¡Œè¦æ±‚ã€‘
        1. Generator ç”Ÿæˆçš„ç”¨ä¾‹å¿…é¡»æ˜¯ JSON æ ¼å¼çš„åˆ—è¡¨ï¼Œæ¯ä¸ªç”¨ä¾‹åŒ…å«ï¼š
           - case_title: ç”¨ä¾‹æ ‡é¢˜
           - steps: æµ‹è¯•æ­¥éª¤åˆ—è¡¨
           - priority: ä¼˜å…ˆçº§
           - case_type: ç”¨ä¾‹ç±»å‹
        2. Reviewer å®¡æŸ¥åï¼Œéœ€è¦ä¸ºæ¯ä¸ªç”¨ä¾‹æ·»åŠ ï¼š
           - requirement_id: åŠŸèƒ½IDï¼Œå¿…é¡»ä¸º {req_id}
           - quality_score: è´¨é‡è¯„åˆ†
           - review_comments: è¯„å®¡æ„è§
        3. Reviewer è°ƒç”¨ save_case å·¥å…·æ—¶ï¼Œå¿…é¡»ä¸ºæ¯ä¸ªç”¨ä¾‹å•ç‹¬è°ƒç”¨ï¼Œç¡®ä¿æ¯ä¸ªç”¨ä¾‹éƒ½åŒ…å« requirement_id å­—æ®µã€‚
        4. ä¸¥ç¦å°†æ‰€æœ‰ç”¨ä¾‹åŒ…è£…åœ¨ä¸€ä¸ªåŒ…å«'case_list'é”®çš„å¯¹è±¡ä¸­ä¼ é€’ç»™save_caseå·¥å…·ã€‚
        5. å¦‚æœæ•°é‡è¾ƒå¤šï¼Œä½ å¯ä»¥åˆ†å¤šæ¬¡ï¼ˆå¤šè½®å¯¹è¯ï¼‰ç”Ÿæˆï¼Œæ¯æ¬¡ç”Ÿæˆ 5 æ¡ï¼Œç›´åˆ°å‡‘å¤Ÿæ•°é‡ã€‚

        ã€é‡è¦æ‰§è¡ŒæŒ‡ä»¤ã€‘
        Generatorï¼Œè¯·ç«‹å³å¼€å§‹å·¥ä½œï¼
        è¯·å…ˆå›å¤ä¸€å¥ï¼šâ€œæ”¶åˆ°ï¼Œæ­£åœ¨ä¸º [ID:{req_id}] ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹...â€ï¼Œç„¶åç´§æ¥ç€è¾“å‡º JSON æ•°æ®ã€‚
        **ä¸è¦ä¿æŒæ²‰é»˜ï¼**
        """


        # --- 5. åˆå§‹åŒ–é€šç”¨æµå¼å¤„ç†å™¨ ---
        processor = AutoGenStreamProcessor(
            agent_names=AGENT_NAMES_MAP,
            tool_names=TOOL_NAMES_MAP,
            # æ³¨å†Œç‰¹å®šçš„è§£æé€»è¾‘
            custom_text_parsers={
                "test_generator": parse_generator_output
            }
        )

        # --- 6. å¯åŠ¨æµå¹¶ç§»äº¤å¤„ç† ---
        # team.run_stream è¿”å›çš„æ˜¯åŸå§‹è¿­ä»£å™¨ï¼Œç›´æ¥ä¼ ç»™ processor è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†
        raw_stream = team.run_stream(task=task_prompt)

        async for sse_event in processor.process_stream(raw_stream):
            yield sse_event

        print("âœ… [DEBUG] run_case_generation_stream æ‰§è¡Œå®Œæ¯•")

    except Exception as e:
        # --- 7. å…¨å±€å¼‚å¸¸æ•è· ---
        traceback.print_exc()
        print(f"âŒ [FATAL ERROR] ä¸šåŠ¡é€»è¾‘å±‚å´©æºƒ: {e}")

        # å‘é€é”™è¯¯æ¶ˆæ¯ç»™å‰ç«¯
        err_json = json.dumps({
            "type": "log",
            "source": "åç«¯å´©æºƒ",
            "content": f"ç³»ç»Ÿé”™è¯¯: {str(e)}"
        }, ensure_ascii=False)
        yield format_sse("message", err_json)

        # å‘é€ç©ºçš„ç»“æŸä¿¡å·ï¼Œé¿å…å‰ç«¯æ— é™ç­‰å¾…
        yield format_sse("finish", "{}")




# -------------------------------------------------------------------------
async def run_batch_functional_generation_stream(ids: list[int], target_count_per_item: int = 5):
    """
    æ‰¹é‡ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ (æ•°æ®æºï¼šfunctional_points è¡¨)
    """
    print(f"ğŸš€ [Batch Functional Stream] IDs={ids}")

    # 1. è·å–æ•°æ®
    items = get_batch_functional_points(ids)
    total = len(items)

    yield format_sse("message", json.dumps({
        "type": "log", "source": "ç³»ç»Ÿé€šçŸ¥",
        "content": f"ğŸ“¦ æ”¶åˆ°æ‰¹é‡ä»»åŠ¡ï¼Œå…± {total} ä¸ªæ­£å¼éœ€æ±‚ç‚¹å¾…å¤„ç†..."
    }, ensure_ascii=False))

    success_count = 0

    # 2. å¾ªç¯å¤„ç†
    for index, item in enumerate(items):
        current_num = index + 1
        req_id = item['id']
        feature_name = item['feature_name']
        # å…¼å®¹ä¸åŒå­—æ®µå
        desc = item.get('description', '') or item.get('feature_name', '')

        yield format_sse("message", json.dumps({
            "type": "log", "source": "ç³»ç»Ÿè°ƒåº¦",
            "content": f"\nğŸ”„ [è¿›åº¦ {current_num}/{total}] æ­£åœ¨å¤„ç†ï¼š{feature_name}..."
        }, ensure_ascii=False))

        try:
            # å¤ç”¨å•æ¡ç”Ÿæˆé€»è¾‘
            async for sse_event in run_case_generation_stream(
                    req_id=req_id,
                    feature_name=feature_name,
                    desc=desc,
                    target_count=target_count_per_item,
                    mode="new",
                    domain='base'
            ):
                # è¿‡æ»¤æ‰å•æ¡ä»»åŠ¡çš„ç»“æŸä¿¡å·
                if "event: finish" not in sse_event:
                    yield sse_event

            success_count += 1

        except Exception as e:
            traceback.print_exc()
            yield format_sse("message", json.dumps({
                "type": "log", "source": "ç³»ç»Ÿé”™è¯¯", "content": f"ID {req_id} å¤„ç†å¤±è´¥: {str(e)}"
            }, ensure_ascii=False))

    # 3. ç»“æŸ
    yield format_sse("finish", json.dumps({"batch_total": total, "success": success_count}, ensure_ascii=False))